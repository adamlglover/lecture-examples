{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import re\n",
    "import pdb\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question a: Setting up the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_url = \"https://en.wikipedia.org\"\n",
    "index_ref = \"/wiki/List_of_accidents_and_incidents_involving_commercial_aircraft\"\n",
    "index_html = urlopen(base_url + index_ref)\n",
    "index = BeautifulSoup(index_html, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the `<li>` tags\n",
    "\n",
    "From inspecting the source code, we can see that every item is within `<li>` tags - in some cases several tags for some days like September 11, 2001. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = index.find_all('li')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling special dates with multiple accidents\n",
    "\n",
    "However, there are some elements in our list that contain another list of dates, which look something like this:\n",
    "\n",
    "`<li><b><a href=\"/wiki/1950_Air_France_multiple_Douglas_DC-4_accidents\" title=\"1950 Air France multiple Douglas DC-4 accidents\">1950 Air France multiple Douglas DC-4 accidents</a></b>:\n",
    " <ul>\n",
    " <li>June 12 – An Air France Douglas DC-4 (F-BBDE) on a flight from Saigon to Paris crashes in the Arabian Sea while on approach to Bahrain Airport, killing 46 of 52 on board.</li>\n",
    " <li>June 14 – An Air France Douglas DC-4, F-BBDM, crashes in the Arabian Sea while on approach to Bahrain Airport, killing 40 of 53 on board. This aircraft was operating on the same flight route as F-BBDE.</li>\n",
    " </ul>\n",
    " </li>`\n",
    "\n",
    "We'll need to make sure we can handle these cases. Additionally, since there are `<li>` tags within this block, the `<li>June 12...</li>` and `<li>June 14...</li>` will appear again in our ResultSet. We should get rid of these duplicates.  \n",
    "\n",
    "Looking at the HTML above, the duplicated `<li>` entries won't have both links and date separators in them, so that's one way we can drop them. Then we'll save rows from the interior `<li>` tags, supplementing link information from the parent if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the entry for September 11 is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li>September 11 – <b><a href=\"/wiki/September_11_attacks\" title=\"September 11 attacks\">September 11 attacks</a></b>\n",
       "<ul>\n",
       "<li><b><a href=\"/wiki/American_Airlines_Flight_11\" title=\"American Airlines Flight 11\">American Airlines Flight 11</a></b>, a Boeing 767-200ER with 92 people on board, is hijacked after taking off from Boston, and is flown into the north tower of the World Trade Center in New York City; all on board are killed as well as others on the ground and in the building.</li>\n",
       "<li><b><a href=\"/wiki/United_Airlines_Flight_175\" title=\"United Airlines Flight 175\">United Airlines Flight 175</a></b>, a Boeing 767-200 with 65 people on board, is hijacked after taking off from Boston and is flown into the south tower of the World Trade Center in New York City; all on board are killed as well as others on the ground and in the building; the collapse of both towers brings the total death toll from the two crashes to at least 2,759, <b>the worst disaster involving commercial aircraft</b>.</li>\n",
       "<li><b><a href=\"/wiki/American_Airlines_Flight_77\" title=\"American Airlines Flight 77\">American Airlines Flight 77</a></b>, a Boeing 757-200 with 64 people on board, is hijacked after taking off from Dulles International Airport and is flown into The Pentagon; all on board are killed as well as 125 people in the building and on the ground.</li>\n",
       "<li><b><a href=\"/wiki/United_Airlines_Flight_93\" title=\"United Airlines Flight 93\">United Airlines Flight 93</a></b>, a Boeing 757-200 with 44 people on board, is hijacked after taking off from Newark, New Jersey; passengers struggle with the hijackers, and the aircraft crashes in a field near Shanksville, Pennsylvania, killing all on board.</li>\n",
       "</ul>\n",
       "</li>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[829]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But then there are also separate entries for each `<li>` in the list inside: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li><b><a href=\"/wiki/American_Airlines_Flight_11\" title=\"American Airlines Flight 11\">American Airlines Flight 11</a></b>, a Boeing 767-200ER with 92 people on board, is hijacked after taking off from Boston, and is flown into the north tower of the World Trade Center in New York City; all on board are killed as well as others on the ground and in the building.</li>,\n",
       " <li><b><a href=\"/wiki/United_Airlines_Flight_175\" title=\"United Airlines Flight 175\">United Airlines Flight 175</a></b>, a Boeing 767-200 with 65 people on board, is hijacked after taking off from Boston and is flown into the south tower of the World Trade Center in New York City; all on board are killed as well as others on the ground and in the building; the collapse of both towers brings the total death toll from the two crashes to at least 2,759, <b>the worst disaster involving commercial aircraft</b>.</li>,\n",
       " <li><b><a href=\"/wiki/American_Airlines_Flight_77\" title=\"American Airlines Flight 77\">American Airlines Flight 77</a></b>, a Boeing 757-200 with 64 people on board, is hijacked after taking off from Dulles International Airport and is flown into The Pentagon; all on board are killed as well as 125 people in the building and on the ground.</li>,\n",
       " <li><b><a href=\"/wiki/United_Airlines_Flight_93\" title=\"United Airlines Flight 93\">United Airlines Flight 93</a></b>, a Boeing 757-200 with 44 people on board, is hijacked after taking off from Newark, New Jersey; passengers struggle with the hijackers, and the aircraft crashes in a field near Shanksville, Pennsylvania, killing all on board.</li>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[830:834]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting data from the HTML\n",
    "\n",
    "Let's take a look at one of the entries in our results containing only a list element defined by `<li>` in the page to see how we can select each piece of data we want to save. We'll store these items in lists. \n",
    "\n",
    "Here we show how to extract pieces of data from the html:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wiki/1919_Verona_Caproni_Ca.48_crash'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].find('a').get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'August 2 – A Caproni Ca.48 crashes at Verona, Italy, during a flight from Venice to Taliedo, Milan, killing all on board (14, 15, or 17 people, according to different sources).'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['August 2',\n",
       " 'A Caproni Ca.48 crashes at Verona, Italy, during a flight from Venice to Taliedo, Milan, killing all on board (14, 15, or 17 people, according to different sources).']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].text.split(' – ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'August 2'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].text.split(' – ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Caproni Ca.48 crashes at Verona, Italy, during a flight from Venice to Taliedo, Milan, killing all on board (14, 15, or 17 people, according to different sources).'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].text.split(' – ')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over all `<li>` elements and extract information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write a function that will handle the fact that the date separator changes during the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date_separator(html_fragment):\n",
    "    # Date separator changes throughout the document, so let's handle both\n",
    "    if ' – ' in html_fragment.text:\n",
    "        return '–'\n",
    "    elif ' - ' in html_fragment.text:\n",
    "        return '-'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function that will take each `<li>` and extract the crash details (month, day, link, and text description) from each element. We should also make sure that we handle the cases where there are several crashes per `<li>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_details(html_fragment):\n",
    "    # these lists may have one or more elements when returned\n",
    "    bdates, blinks, bdescrips = [], [], []\n",
    "    \n",
    "    if html_fragment.find_all('li') == []:\n",
    "        # Then there is only one crash for this bullet\n",
    "        separator = get_date_separator(html_fragment)    \n",
    "        blinks.append(html_fragment.find('a').get('href'))\n",
    "        bdates.append(html_fragment.text.split(separator)[0].strip())\n",
    "        bdescrips.append(html_fragment.text.split(separator)[1].strip())\n",
    "\n",
    "    else:\n",
    "        # Then there are multiple crashes for this bullet\n",
    "        for bullet in html_fragment.find_all('li'):\n",
    "\n",
    "            # Dates might appear in current or parent <li>\n",
    "            separator = get_date_separator(bullet)\n",
    "            if separator != None:\n",
    "                bdates.append(bullet.text.split(separator)[0].strip())\n",
    "                bdescrips.append(bullet.text.split(separator)[1].strip())\n",
    "            else:\n",
    "                parent_separator = get_date_separator(html_fragment)\n",
    "                bdates.append(html_fragment.text.split(parent_separator)[0].strip())\n",
    "                bdescrips.append(bullet.text.strip())                \n",
    "\n",
    "            # Relevant link might appear in current or parent <li>\n",
    "            if bullet.find('a') == None:\n",
    "                blinks.append(html_fragment.find('a').get('href'))\n",
    "            else:\n",
    "                blinks.append(bullet.find('a').get('href'))\n",
    "                \n",
    "    return bdates, blinks, bdescrips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates_month_day, links, descriptions = [], [], []\n",
    "for each_li in result:\n",
    "    if (' – ' in each_li.text or ' - ' in each_li.text) and each_li.find('a') != None:\n",
    "        lis_dates, lis_links, lis_descrips = extract_details(each_li)\n",
    "        dates_month_day += lis_dates\n",
    "        links += lis_links\n",
    "        descriptions += lis_descrips\n",
    "    else:\n",
    "        # If neither condition is true, then we hit duplicate or extra links\n",
    "        # elsewhere in the page so we can skip these and throw them away\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check the lengths of each list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1066, 1066, 1066)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dates_month_day), len(links), len(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Time to make the DataFrame, which we can do by passing a Python dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'date': dates_month_day, 'link': links, 'description': descriptions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>August 2</td>\n",
       "      <td>A Caproni Ca.48 crashes at Verona, Italy, duri...</td>\n",
       "      <td>/wiki/1919_Verona_Caproni_Ca.48_crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>April 7</td>\n",
       "      <td>In the first mid-air collision of airliners, a...</td>\n",
       "      <td>/wiki/First_mid-air_collision_of_airliners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>May 14</td>\n",
       "      <td>An Air Union Farman F.60 Goliath crashes near ...</td>\n",
       "      <td>/wiki/May_1923_Air_Union_Farman_Goliath_crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>August 27</td>\n",
       "      <td>An Air Union Farman F.60 Goliath crashes near ...</td>\n",
       "      <td>/wiki/August_1923_Air_Union_Farman_Goliath_crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>December 24</td>\n",
       "      <td>An Imperial Airways de Havilland DH.34 crashes...</td>\n",
       "      <td>/wiki/1924_Imperial_Airways_de_Havilland_DH.34...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                        description  \\\n",
       "0     August 2  A Caproni Ca.48 crashes at Verona, Italy, duri...   \n",
       "1      April 7  In the first mid-air collision of airliners, a...   \n",
       "2       May 14  An Air Union Farman F.60 Goliath crashes near ...   \n",
       "3    August 27  An Air Union Farman F.60 Goliath crashes near ...   \n",
       "4  December 24  An Imperial Airways de Havilland DH.34 crashes...   \n",
       "\n",
       "                                                link  \n",
       "0              /wiki/1919_Verona_Caproni_Ca.48_crash  \n",
       "1         /wiki/First_mid-air_collision_of_airliners  \n",
       "2      /wiki/May_1923_Air_Union_Farman_Goliath_crash  \n",
       "3   /wiki/August_1923_Air_Union_Farman_Goliath_crash  \n",
       "4  /wiki/1924_Imperial_Airways_de_Havilland_DH.34...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we did everything right for the weird cases by checking one of the bullets that had multiple crashes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>September 11</td>\n",
       "      <td>A President Airlines Douglas DC-6 crashes shor...</td>\n",
       "      <td>/wiki/1961_President_Airlines_Douglas_DC-6_crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>September 11</td>\n",
       "      <td>Air France Flight 1611, a Sud Aviation SE-210 ...</td>\n",
       "      <td>/wiki/Air_France_Flight_1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>September 11</td>\n",
       "      <td>JAT Airways Flight 769, a Sud Aviation Caravel...</td>\n",
       "      <td>/wiki/JAT_Airways_Flight_769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>September 11</td>\n",
       "      <td>Eastern Air Lines Flight 212, a McDonnell Doug...</td>\n",
       "      <td>/wiki/Eastern_Air_Lines_Flight_212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>September 11</td>\n",
       "      <td>Continental Express Flight 2574, an Embraer EM...</td>\n",
       "      <td>/wiki/Continental_Express_Flight_2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>September 11</td>\n",
       "      <td>American Airlines Flight 11, a Boeing 767-200E...</td>\n",
       "      <td>/wiki/American_Airlines_Flight_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>September 11</td>\n",
       "      <td>United Airlines Flight 175, a Boeing 767-200 w...</td>\n",
       "      <td>/wiki/United_Airlines_Flight_175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>September 11</td>\n",
       "      <td>American Airlines Flight 77, a Boeing 757-200 ...</td>\n",
       "      <td>/wiki/American_Airlines_Flight_77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>September 11</td>\n",
       "      <td>United Airlines Flight 93, a Boeing 757-200 wi...</td>\n",
       "      <td>/wiki/United_Airlines_Flight_93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date                                        description  \\\n",
       "222  September 11  A President Airlines Douglas DC-6 crashes shor...   \n",
       "323  September 11  Air France Flight 1611, a Sud Aviation SE-210 ...   \n",
       "417  September 11  JAT Airways Flight 769, a Sud Aviation Caravel...   \n",
       "429  September 11  Eastern Air Lines Flight 212, a McDonnell Doug...   \n",
       "680  September 11  Continental Express Flight 2574, an Embraer EM...   \n",
       "825  September 11  American Airlines Flight 11, a Boeing 767-200E...   \n",
       "826  September 11  United Airlines Flight 175, a Boeing 767-200 w...   \n",
       "827  September 11  American Airlines Flight 77, a Boeing 757-200 ...   \n",
       "828  September 11  United Airlines Flight 93, a Boeing 757-200 wi...   \n",
       "\n",
       "                                                 link  \n",
       "222  /wiki/1961_President_Airlines_Douglas_DC-6_crash  \n",
       "323                      /wiki/Air_France_Flight_1611  \n",
       "417                      /wiki/JAT_Airways_Flight_769  \n",
       "429                /wiki/Eastern_Air_Lines_Flight_212  \n",
       "680             /wiki/Continental_Express_Flight_2574  \n",
       "825                 /wiki/American_Airlines_Flight_11  \n",
       "826                  /wiki/United_Airlines_Flight_175  \n",
       "827                 /wiki/American_Airlines_Flight_77  \n",
       "828                   /wiki/United_Airlines_Flight_93  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.date == 'September 11']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like exactly what we expected. Now let's proceed with clicking the links so we can add in the year. We have to click those links anyway to extract the additional crash details, so let's just grab the years from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('crashes_question_starter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['description', 'link']].to_csv('crashes_no_extra_credit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question b: Completing the dataframe with details\n",
    "\n",
    "I'll rate limit my requests by using the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def try_request(url):\n",
    "    html = urlopen(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    return BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting elements from the summary page\n",
    "\n",
    "We will write a function to extract elements from a list of table rows (defined by `<tr>`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_summary(trs):\n",
    "    date_w_year, passengers, crew, fatalities, survivors = '', 0, 0, 0, 0\n",
    "    registration, origins, destination = 'No data', 'No data', 'No data'\n",
    "\n",
    "    for each_tr in trs:\n",
    "        if each_tr.find('th', text = re.compile('Destination')) != None:\n",
    "            try:\n",
    "                destination = each_tr.td.text\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Date')) != None:\n",
    "            try:\n",
    "                date_w_year = each_tr.td.text   \n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Passengers')) != None:\n",
    "            try:\n",
    "                passengers = extract_numbers(each_tr.td.text, passengers)\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Crew')) != None:\n",
    "            try:\n",
    "                crew = extract_numbers(each_tr.td.text, passengers)\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Fatalities')) != None:\n",
    "            try:\n",
    "                fatalities = extract_numbers(each_tr.td.text, passengers)\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Survivors')) != None:\n",
    "            try:\n",
    "                survivors = extract_numbers(each_tr.td.text, passengers)\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Flight origin')) != None:\n",
    "            try:\n",
    "                origins = each_tr.td.text\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Registration')) != None:\n",
    "            try:\n",
    "                registration = each_tr.td.text\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return {'destination': destination,\n",
    "            'date': date_w_year,\n",
    "            'passengers': passengers,\n",
    "            'crew': crew,\n",
    "            'fatalities': fatalities,\n",
    "            'survivors': survivors,\n",
    "            'origins': origins,\n",
    "            'registration': registration}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection of the text of each summary, we can see that there are some cases where in addition to (or instead of) an integer, there is some extraneous text or just a string like \"all\", \"unknown\", or \"none\". Let's handle these special cases and extract numbers in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_numbers(td_text, passengers):\n",
    "    \"\"\"\n",
    "    Function that handles table data rows to extract numbers.\n",
    "    Handles special cases where there are strings like all, none, etc. in the text\n",
    "    \"\"\"\n",
    "\n",
    "    number_regex = re.compile('\\d+')\n",
    "    all_regex = re.compile('ll')\n",
    "    none_regex = re.compile('one')\n",
    "    unknown_regex = re.compile('nknown')\n",
    "    \n",
    "    try:\n",
    "        data_element = int(number_regex.findall(td_text)[0])\n",
    "    except:\n",
    "        if len(all_regex.findall(td_text)) >= 1:\n",
    "            data_element = passengers\n",
    "        elif len(none_regex.findall(td_text)) >= 1:\n",
    "            data_element = 0\n",
    "        elif len(unknown_regex.findall(td_text)) >= 1:\n",
    "            data_element = 0\n",
    "        else:\n",
    "            data_element = 0\n",
    "    \n",
    "    return data_element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping each page\n",
    "\n",
    "Now let's use these functions to scrape each link. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define lists we use to store our results\n",
    "dates_w_year, passengers, crew, fatalities, survivors = [], [], [], [], []\n",
    "registration, origins, destination = [], [], []\n",
    "\n",
    "for row in links:\n",
    "    # Get HTML of detail page\n",
    "    summary_html = try_request(base_url + row)\n",
    "    trs = summary_html.find_all('tr')\n",
    "\n",
    "    # Extract data from summary HTML\n",
    "    summary = extract_summary(trs)\n",
    "    \n",
    "    # Save the data for this page in our lists\n",
    "    dates_w_year.append(summary['date'])   \n",
    "    passengers.append(summary['passengers'])\n",
    "    crew.append(summary['crew'])\n",
    "    fatalities.append(summary['fatalities'])\n",
    "    survivors.append(summary['survivors'])\n",
    "    origins.append(summary['origins'])\n",
    "    registration.append(summary['registration'])\n",
    "    destination.append(summary['destination'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sanity check the lengths of these lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1066, 1066, 1066, 1066, 1066, 1066, 1066, 1066)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(destination), len(origins), len(registration), len(dates_w_year), len(passengers), len(crew), len(fatalities), len(survivors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame({'date': dates_w_year, 'link': links, 'description': descriptions, 'passengers': passengers,\n",
    "                       'crew': crew, 'fatalities': fatalities, 'survivors': survivors,\n",
    "                       'registration': registration, 'flight origin': origins, 'destination': destination})\n",
    "# save all this scraped stuff!\n",
    "df_full.to_csv('all_data_rescraped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('all_data_rescraped.csv')\n",
    "dates_w_year = df_full['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_full.columns\n",
    "df_full.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Clean up dates and format them as datetimes\n",
    "\n",
    "The formatting of the dates is not so great, so let's just clean that up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    August 2, 1919 (1919-08-02)\n",
       "1                   7 April 1922\n",
       "2       14 May 1923 (1923-05-14)\n",
       "3    27 August 1923 (1923-08-27)\n",
       "4               24 December 1924\n",
       "5                 18 August 1926\n",
       "6                 2 October 1926\n",
       "7                 22 August 1927\n",
       "8                   13 July 1928\n",
       "9                   17 June 1929\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_w_year[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove commas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_dates = [str(d).replace(',', '') for d in dates_w_year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dates have month first. Some dates have date first. Let's make them consistent while also getting rid of extraneous information appended to the end of the date (like links to references). We'll write our own function to parse dates because we like to do fun and cool things like that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "months = list(calendar.month_name)\n",
    "days = list(calendar.day_name)\n",
    "dates = [str(d) for d in list(range(1, 32))]\n",
    "years = [str(y) for y in list(range(1900, 2017))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_date_strings(text):\n",
    "    split_row = text.split()\n",
    "    month, day, year, date = '', '', '', ''\n",
    "\n",
    "    for each in split_row[0:4]:\n",
    "        if each in months:\n",
    "            month = each\n",
    "        elif each in days:\n",
    "            day = each\n",
    "        elif each in years:\n",
    "            year = each\n",
    "        elif each in dates:\n",
    "            date = each\n",
    "        else:\n",
    "            pass\n",
    "    return {'month': month,\n",
    "           'day': day,\n",
    "           'year': year,\n",
    "           'date': date}\n",
    "\n",
    "\n",
    "def fix_dates(datecol):\n",
    "    correctedcol = []\n",
    "\n",
    "    for row in datecol:\n",
    "        parsed_date = parse_date_strings(row)\n",
    "        correctedcol.append('{} {} {}'.format(parsed_date['date'],\n",
    "                                              parsed_date['month'],\n",
    "                                              parsed_date['year']))\n",
    "\n",
    "    return correctedcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datescol = fix_dates(cleaned_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 August 1919',\n",
       " '7 April 1922',\n",
       " '14 May 1923',\n",
       " '27 August 1923',\n",
       " '24 December 1924']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datescol[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that our dates are nicely formatted and can create them as datetime objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates_datetime = pd.to_datetime(datescol, format='%d %B %Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_full['date'] = dates_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crew</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>destination</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>flight origin</th>\n",
       "      <th>link</th>\n",
       "      <th>passengers</th>\n",
       "      <th>registration</th>\n",
       "      <th>survivors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1919-08-02</td>\n",
       "      <td>A Caproni Ca.48 crashes at Verona, Italy, duri...</td>\n",
       "      <td>Taliedo, Milan, Italy</td>\n",
       "      <td>14</td>\n",
       "      <td>Venice, Italy</td>\n",
       "      <td>/wiki/1919_Verona_Caproni_Ca.48_crash</td>\n",
       "      <td>12</td>\n",
       "      <td>No data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1922-04-07</td>\n",
       "      <td>In the first mid-air collision of airliners, a...</td>\n",
       "      <td>Le Bourget, Paris</td>\n",
       "      <td>2</td>\n",
       "      <td>Croydon</td>\n",
       "      <td>/wiki/First_mid-air_collision_of_airliners</td>\n",
       "      <td>0</td>\n",
       "      <td>G-EAWO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1923-05-14</td>\n",
       "      <td>An Air Union Farman F.60 Goliath crashes near ...</td>\n",
       "      <td>Croydon, Surrey, United Kingdom</td>\n",
       "      <td>6</td>\n",
       "      <td>Le Bourget, Paris, France</td>\n",
       "      <td>/wiki/May_1923_Air_Union_Farman_Goliath_crash</td>\n",
       "      <td>4</td>\n",
       "      <td>F-AEBY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1923-08-27</td>\n",
       "      <td>An Air Union Farman F.60 Goliath crashes near ...</td>\n",
       "      <td>Croydon Airport, Surrey, United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>Le Bourget Airport, Paris, France</td>\n",
       "      <td>/wiki/August_1923_Air_Union_Farman_Goliath_crash</td>\n",
       "      <td>11</td>\n",
       "      <td>F-AECB</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1924-12-24</td>\n",
       "      <td>An Imperial Airways de Havilland DH.34 crashes...</td>\n",
       "      <td>Le Bourget, Paris, France</td>\n",
       "      <td>8</td>\n",
       "      <td>Croydon, Surrey, United Kingdom</td>\n",
       "      <td>/wiki/1924_Imperial_Airways_de_Havilland_DH.34...</td>\n",
       "      <td>7</td>\n",
       "      <td>G-EBBX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   crew       date                                        description  \\\n",
       "0     2 1919-08-02  A Caproni Ca.48 crashes at Verona, Italy, duri...   \n",
       "1     2 1922-04-07  In the first mid-air collision of airliners, a...   \n",
       "2     2 1923-05-14  An Air Union Farman F.60 Goliath crashes near ...   \n",
       "3     2 1923-08-27  An Air Union Farman F.60 Goliath crashes near ...   \n",
       "4     1 1924-12-24  An Imperial Airways de Havilland DH.34 crashes...   \n",
       "\n",
       "                               destination  fatalities  \\\n",
       "0                    Taliedo, Milan, Italy          14   \n",
       "1                        Le Bourget, Paris           2   \n",
       "2          Croydon, Surrey, United Kingdom           6   \n",
       "3  Croydon Airport, Surrey, United Kingdom           1   \n",
       "4                Le Bourget, Paris, France           8   \n",
       "\n",
       "                       flight origin  \\\n",
       "0                      Venice, Italy   \n",
       "1                            Croydon   \n",
       "2          Le Bourget, Paris, France   \n",
       "3  Le Bourget Airport, Paris, France   \n",
       "4    Croydon, Surrey, United Kingdom   \n",
       "\n",
       "                                                link  passengers registration  \\\n",
       "0              /wiki/1919_Verona_Caproni_Ca.48_crash          12      No data   \n",
       "1         /wiki/First_mid-air_collision_of_airliners           0       G-EAWO   \n",
       "2      /wiki/May_1923_Air_Union_Farman_Goliath_crash           4       F-AEBY   \n",
       "3   /wiki/August_1923_Air_Union_Farman_Goliath_crash          11       F-AECB   \n",
       "4  /wiki/1924_Imperial_Airways_de_Havilland_DH.34...           7       G-EBBX   \n",
       "\n",
       "   survivors  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3         12  \n",
       "4          0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame({'date': dates_datetime, 'link': links, 'description': descriptions, 'passengers': passengers,\n",
    "                       'crew': crew, 'fatalities': fatalities, 'survivors': survivors,\n",
    "                       'registration': registration, 'flight origin': origins, 'destination': destination})\n",
    "# save all this scraped stuff!\n",
    "df_full.to_csv('final_dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Doing part b while handling the special cases where there are multiple summaries per page\n",
    "\n",
    "I told you to ignore this for the sake of simplifying this assignment, but it is the case that there are multiple summaries on a couple pages, for example:\n",
    "\n",
    "https://en.wikipedia.org/wiki/1950_Air_France_multiple_Douglas_DC-4_accidents\n",
    "\n",
    "These we can separate using the dates. \n",
    "\n",
    "However, in addition to this, there are some cases where planes crash into one another. In these cases, the summaries are separated into two tables, one for each page, for example:\n",
    "\n",
    "https://en.wikipedia.org/wiki/1922_Picardie_mid-air_collision\n",
    "\n",
    "We could handle this in two ways: Sum the numbers for passengers, fatalities, etc. Or we could instead create two rows for these crashes. \n",
    "\n",
    "We could handle both these cases by doing the following (pseudocode):\n",
    "\n",
    "```\n",
    "if there are multiple tables\n",
    "        get the summary details for the appropriate date\n",
    "else if there is one table\n",
    "        get the summary details for each summary table and sum them (this is a collision)\n",
    "```\n",
    "\n",
    "We will create a new function `extract_summaries()` that will implement this approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_summaries(tables, relevant_date):\n",
    "\n",
    "    if len(tables) == 1:\n",
    "        result = extract_single_table_summary(tables[0])\n",
    "    else:\n",
    "        result = extract_relevant_table_summary(tables, relevant_date)\n",
    "    \n",
    "    return {'destination': result['destination'],\n",
    "            'date': result['date'],\n",
    "            'passengers': result['passengers'],\n",
    "            'crew': result['crew'],\n",
    "            'fatalities': result['fatalities'],\n",
    "            'survivors': result['survivors'],\n",
    "            'origins': result['origins'],\n",
    "            'registration': result['registration']}\n",
    "\n",
    "\n",
    "def pick_out_table(tables, relevant_date):\n",
    "        \n",
    "    for table in tables:\n",
    "        trs = table.find_all('tr')\n",
    "        for each_tr in trs:\n",
    "            if each_tr.find('th', text = re.compile('Date')) != None:\n",
    "                \n",
    "                # Clean and parse date\n",
    "                date = each_tr.td.text.replace(',', '')\n",
    "                parsed_date = parse_date_strings(date)\n",
    "                \n",
    "                if (parsed_date['month'] == relevant_date.split()[0] \n",
    "                    and parsed_date['date'] == relevant_date.split()[1]):\n",
    "                    return table\n",
    "\n",
    "    return tables[0]\n",
    "\n",
    "\n",
    "def extract_relevant_table_summary(tables, relevant_date):\n",
    "    date_w_year, passengers, crew, fatalities, survivors = '', 0, 0, 0, 0\n",
    "    registration, origins, destination = '', '', ''\n",
    "\n",
    "    table = pick_out_table(tables, relevant_date)\n",
    "    \n",
    "    trs = table.find_all('tr')\n",
    "        \n",
    "    for each_tr in trs:\n",
    "        if each_tr.find('th', text = re.compile('Destination')) != None:\n",
    "            try:\n",
    "                destination = each_tr.td.text\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Date')) != None:\n",
    "            try:\n",
    "                date_w_year = each_tr.td.text   \n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Passengers')) != None:\n",
    "            try:\n",
    "                passengers = extract_numbers(each_tr.td.text, passengers)\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Crew')) != None:\n",
    "            try:\n",
    "                crew = extract_numbers(each_tr.td.text, passengers)\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Fatalities')) != None:\n",
    "            try:\n",
    "                fatalities = extract_numbers(each_tr.td.text, passengers)\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Survivors')) != None:\n",
    "            try:\n",
    "                survivors = extract_numbers(each_tr.td.text, passengers)\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Flight origin')) != None:\n",
    "            try:\n",
    "                origins = each_tr.td.text\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Registration')) != None:\n",
    "            try:\n",
    "                registration = each_tr.td.text\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return {'destination': destination.strip(),\n",
    "            'date': date_w_year,\n",
    "            'passengers': passengers,\n",
    "            'crew': crew,\n",
    "            'fatalities': fatalities,\n",
    "            'survivors': survivors,\n",
    "            'origins': origins.strip(),\n",
    "            'registration': registration.strip()}\n",
    "\n",
    "\n",
    "def extract_single_table_summary(table):\n",
    "    date_w_year, passengers, crew, fatalities, survivors = '', 0, 0, 0, 0\n",
    "    registration, origins, destination = '', '', ''\n",
    "\n",
    "    trs = table.find_all('tr')\n",
    "        \n",
    "    for each_tr in trs:\n",
    "        if each_tr.find('th', text = re.compile('Destination')) != None:\n",
    "            try:\n",
    "                destination += '    ' + each_tr.td.text\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Date')) != None:\n",
    "            try:\n",
    "                date_w_year = each_tr.td.text   \n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Passengers')) != None:\n",
    "            try:\n",
    "                passengers += extract_numbers(each_tr.td.text, passengers)\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Crew')) != None:\n",
    "            try:\n",
    "                crew += extract_numbers(each_tr.td.text, passengers)\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Fatalities')) != None:\n",
    "            try:\n",
    "                fatalities += extract_numbers(each_tr.td.text, passengers)\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Survivors')) != None:\n",
    "            try:\n",
    "                survivors += extract_numbers(each_tr.td.text, passengers)\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Flight origin')) != None:\n",
    "            try:\n",
    "                origins += '    ' + each_tr.td.text\n",
    "            except:\n",
    "                pass\n",
    "        elif each_tr.find('th', text = re.compile('Registration')) != None:\n",
    "            try:\n",
    "                registration += '    ' + each_tr.td.text\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return {'destination': destination.strip(),\n",
    "            'date': date_w_year,\n",
    "            'passengers': passengers,\n",
    "            'crew': crew,\n",
    "            'fatalities': fatalities,\n",
    "            'survivors': survivors,\n",
    "            'origins': origins.strip(),\n",
    "            'registration': registration.strip()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test with the two URLs from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_collision_url = 'https://en.wikipedia.org/wiki/1922_Picardie_mid-air_collision'\n",
    "summary_html = try_request(test_collision_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tables = summary_html.find_all('table', {\"class\" : \"infobox vcard vevent\"})\n",
    "result_updated = extract_summaries(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crew': 4,\n",
       " 'date': '7 April 1922',\n",
       " 'destination': 'Croydon    Le Bourget, Paris',\n",
       " 'fatalities': 7,\n",
       " 'origins': 'Le Bourget, Paris    Croydon',\n",
       " 'passengers': 3,\n",
       " 'registration': 'F-GEAD    G-EAWO',\n",
       " 'survivors': 0}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we can correctly extract a summary table with multiple aircraft in it. \n",
    "\n",
    "Now let's try on a page that has multiple crashes in it *on different days*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_multiple_dates_url = 'https://en.wikipedia.org/wiki/1950_Air_France_multiple_Douglas_DC-4_accidents'\n",
    "summary_html = try_request(test_multiple_dates_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_crash = 'June 12'\n",
    "second_crash = 'June 14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tables = summary_html.find_all('table', {\"class\" : \"infobox vcard vevent\"})\n",
    "result_updated = extract_summaries(tables, first_crash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crew': 8,\n",
       " 'date': '12 June 1950',\n",
       " 'destination': 'Paris, France',\n",
       " 'fatalities': 46,\n",
       " 'origins': 'Saigon, Vietnam',\n",
       " 'passengers': 44,\n",
       " 'registration': 'F-BBDE',\n",
       " 'survivors': 6}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_updated = extract_summaries(tables, second_crash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crew': 8,\n",
       " 'date': '14 June 1950',\n",
       " 'destination': 'Paris, France',\n",
       " 'fatalities': 40,\n",
       " 'origins': 'Saigon, Vietnam',\n",
       " 'passengers': 45,\n",
       " 'registration': 'F-BBDM',\n",
       " 'survivors': 13}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dates_w_year, passengers, crew, fatalities, survivors = [], [], [], [], []\n",
    "registration, origins, destination = [], [], []\n",
    "\n",
    "for num_row in range(len(links)):\n",
    "    # Get HTML of detail page\n",
    "    summary_html = try_request(base_url + links[num_row])\n",
    "    \n",
    "    # Get tables that are in these sidebars (mostly one, but sometimes multiple)\n",
    "    tables = summary_html.find_all('table', {\"class\" : [\"infobox\", \"vcard\"]})\n",
    "\n",
    "    # Extract data from summary HTML\n",
    "    summary = extract_summaries(tables, dates_month_day[num_row])\n",
    "    \n",
    "    # Save the data for this page in our lists\n",
    "    dates_w_year.append(summary['date'])   \n",
    "    passengers.append(summary['passengers'])\n",
    "    crew.append(summary['crew'])\n",
    "    fatalities.append(summary['fatalities'])\n",
    "    survivors.append(summary['survivors'])\n",
    "    origins.append(summary['origins'])\n",
    "    registration.append(summary['registration'])\n",
    "    destination.append(summary['destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean dates\n",
    "cleaned_dates = [str(d).replace(',', '') for d in dates_w_year]\n",
    "datescol = fix_dates(cleaned_dates)\n",
    "dates_datetime = pd.to_datetime(datescol, format='%d %B %Y', errors='coerce')\n",
    "\n",
    "# Save!\n",
    "df_summary = pd.DataFrame({'date': dates_datetime, 'link': links, 'description': descriptions, 'passengers': passengers,\n",
    "                       'crew': crew, 'fatalities': fatalities, 'survivors': survivors,\n",
    "                       'registration': registration, 'flight origin': origins, 'destination': destination})\n",
    "# save all this scraped stuff!\n",
    "df_summary.to_csv('final_dataframe_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question c: Which were the top 5 most deadly aviation incidents? Report the number of fatalities and the flight origin for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_5_crashes = df_full.sort_values('fatalities', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the top 5 crashes, the number of fatalities and the flight origin was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fatalities</th>\n",
       "      <th>flight origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>520</td>\n",
       "      <td>Haneda Airport, Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>346</td>\n",
       "      <td>Yesilköy Int'l Airport\\nIstanbul, Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>329</td>\n",
       "      <td>Toronto (as Flight 181) Montréal-Mirabel Int'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>301</td>\n",
       "      <td>Quaid-e-Azam Int'l Airport\\nKarachi, Pakistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>298</td>\n",
       "      <td>Amsterdam Airport Schiphol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fatalities                                      flight origin\n",
       "584          520                              Haneda Airport, Tokyo\n",
       "425          346           Yesilköy Int'l Airport\\nIstanbul, Turkey\n",
       "581          329  Toronto (as Flight 181) Montréal-Mirabel Int'l...\n",
       "513          301      Quaid-e-Azam Int'l Airport\\nKarachi, Pakistan\n",
       "1045         298                         Amsterdam Airport Schiphol"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_crashes[['fatalities', 'flight origin']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584     Japan Airlines Flight 123, a Boeing 747, crash...\n",
       "425     Turkish Airlines Flight 981, a McDonnell Dougl...\n",
       "581     Air India Flight 182, a Boeing 747 en route fr...\n",
       "513     Saudia Flight 163, a Lockheed L-1011 Tristar, ...\n",
       "1045    Malaysia Airlines Flight 17, a Boeing 777 en r...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_crashes['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question d: Which flight origin has the highest number of aviation incidents in the last 25 years?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It's 2016, so let's take accidents from 1991 and later and see which is the most common flight origin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This crash is the first one to occur in 1991:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1991-02-01 00:00:00')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.date[672]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recent_incidents = df_full[673:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No data                                                 40\n",
       "Bergen Airport, Norway                                   3\n",
       "Ninoy Aquino International Airport                       3\n",
       "Domodedovo International Airport, Moscow                 3\n",
       "Nnamdi Azikiwe International Airport, Abuja, Nigeria     2\n",
       "Name: flight origin, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_incidents['flight origin'].value_counts()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without de-duplication, Bergen Airport, Ninoy Aquino International Airport, and Domodedovo International Airport in Moscow had the highest number of aviation incidents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of curiosity, let's do this for the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No data                                              127\n",
       "London Heathrow Airport                               10\n",
       "Los Angeles International Airport                      6\n",
       "Los Angeles Int'l Airport                              5\n",
       "Miami International Airport                            5\n",
       "Trondheim Airport, Værnes                              4\n",
       "Cairo International Airport, Egypt                     4\n",
       "Ninoy Aquino International Airport                     3\n",
       "Orly Airport, Paris, France                            3\n",
       "Juanda International Airport, Surabaya, Indonesia      3\n",
       "Name: flight origin, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full['flight origin'].value_counts()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "London Heathrow and LAX (entered twice as two slightly different strings) come out on top, which is not unexpected given the number of flights these airports have. \n",
    "\n",
    "Note that one way we could proceed with de-duplication would be to use the fact that the summary tables actually contain links to their corresponding wikipedia pages. We could link together strings that correspond to the same airport using their common link. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question e: Output as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full.to_json('crashes.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
